{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e341524f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 5% missing data...\n",
      "\n",
      "Processing 10% missing data...\n",
      "\n",
      "Processing 15% missing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/impute/_iterative.py:895: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running model for 5%_casewise imputed data...\n",
      "\n",
      "Running model for 5%_zero imputed data...\n",
      "\n",
      "Running model for 5%_mean imputed data...\n",
      "\n",
      "Running model for 5%_knn imputed data...\n",
      "\n",
      "Running model for 5%_regression imputed data...\n",
      "\n",
      "Running model for 10%_casewise imputed data...\n",
      "\n",
      "Running model for 10%_zero imputed data...\n",
      "\n",
      "Running model for 10%_mean imputed data...\n",
      "\n",
      "Running model for 10%_knn imputed data...\n",
      "\n",
      "Running model for 10%_regression imputed data...\n",
      "\n",
      "Running model for 15%_casewise imputed data...\n",
      "\n",
      "Running model for 15%_zero imputed data...\n",
      "\n",
      "Running model for 15%_mean imputed data...\n",
      "\n",
      "Running model for 15%_knn imputed data...\n",
      "\n",
      "Running model for 15%_regression imputed data...\n",
      "\n",
      "Regression Results for 5% Missing Data:\n",
      "                  MAE     MSE    RMSE\n",
      "5%_casewise    0.7007  0.8853  0.9409\n",
      "5%_zero        0.8046  1.0983  1.0480\n",
      "5%_mean        0.8034  1.0943  1.0461\n",
      "5%_knn         0.8031  1.0972  1.0475\n",
      "5%_regression  0.7989  1.0918  1.0449\n",
      "\n",
      "Regression Results for 10% Missing Data:\n",
      "                   MAE     MSE    RMSE\n",
      "10%_casewise    0.6364  0.6818  0.8257\n",
      "10%_zero        0.8052  1.0970  1.0474\n",
      "10%_mean        0.8066  1.0974  1.0476\n",
      "10%_knn         0.8070  1.0960  1.0469\n",
      "10%_regression  0.7988  1.0916  1.0448\n",
      "\n",
      "Regression Results for 15% Missing Data:\n",
      "                   MAE     MSE    RMSE\n",
      "15%_casewise    1.2284  3.0809  1.7552\n",
      "15%_zero        0.8115  1.1258  1.0610\n",
      "15%_mean        0.8089  1.1176  1.0572\n",
      "15%_knn         0.8157  1.1687  1.0811\n",
      "15%_regression  0.7989  1.0919  1.0449\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "rating_csv = \"/workspaces/codespaces-jupyter/data/rating.csv\"\n",
    "rating_df = pd.read_csv(rating_csv).sample(385, random_state=955)\n",
    "\n",
    "movie_csv = \"/workspaces/codespaces-jupyter/data/movie.csv\"\n",
    "movie_df = pd.read_csv(movie_csv)\n",
    "\n",
    "# Merge the datasets\n",
    "final_df = pd.merge(movie_df, rating_df, on='movieId', how='inner')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "df = final_df.drop(columns=['title', 'timestamp'])\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Convert pipe-separated genres into space-separated strings\n",
    "df['genres'] = df['genres'].str.replace('|', ' ', regex=False)\n",
    "\n",
    "# TF-IDF transformation\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_genres = tfidf.fit_transform(df['genres'])\n",
    "tfidf_genres_df = pd.DataFrame(\n",
    "    tfidf_genres.toarray(), \n",
    "    columns=[f\"tfidf_{genre}\" for genre in tfidf.get_feature_names_out()],\n",
    "    index=df.index\n",
    ")\n",
    "\n",
    "# Drop and replace\n",
    "df = df.drop(columns=['genres'])\n",
    "df = pd.concat([df, tfidf_genres_df], axis=1)\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Store the target variable separately\n",
    "y_full = df['rating']\n",
    "\n",
    "# Create an imputation dataframe by dropping the dependent variable\n",
    "imputation_df = df.drop('rating', axis=1)\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "random.seed(29)\n",
    "np.random.seed(29)\n",
    "\n",
    "# Calculate the total number of values in the dataframe\n",
    "total_values = imputation_df.size\n",
    "\n",
    "# Function to create a dataframe with a specified percentage of missing values\n",
    "def create_missing_df(base_df, percent_missing):\n",
    "    df_missing = base_df.copy()\n",
    "    num_nulls = int(total_values * percent_missing)\n",
    "    indices = [(row, col) for row in range(df_missing.shape[0]) for col in range(df_missing.shape[1])]\n",
    "    random_indices = random.sample(indices, num_nulls)\n",
    "    for row, col in random_indices:\n",
    "        df_missing.iat[row, col] = np.nan\n",
    "    return df_missing\n",
    "\n",
    "# Create dataframes with different levels of missingness\n",
    "df_5 = create_missing_df(imputation_df, 0.05)\n",
    "df_10 = create_missing_df(imputation_df, 0.10)\n",
    "df_15 = create_missing_df(imputation_df, 0.15)\n",
    "\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from fancyimpute import IterativeImputer  # for multivariate regression\n",
    "\n",
    "# Put all missing dataframes into a dictionary for easier looping\n",
    "missing_dfs = {\n",
    "    '5%': df_5,\n",
    "    '10%': df_10,\n",
    "    '15%': df_15\n",
    "}\n",
    "\n",
    "# Store results\n",
    "imputed_dfs = {}\n",
    "\n",
    "for key, df in missing_dfs.items():\n",
    "    print(f\"\\nProcessing {key} missing data...\")\n",
    "\n",
    "    # 1. Case-wise deletion\n",
    "    imputed_dfs[f'{key}_casewise'] = df.dropna()\n",
    "\n",
    "    # 2. Fill with 0\n",
    "    imputed_dfs[f'{key}_zero'] = df.fillna(0)\n",
    "\n",
    "    # 3. Fill with mean\n",
    "    mean_imputer = SimpleImputer(strategy='mean')\n",
    "    imputed_dfs[f'{key}_mean'] = pd.DataFrame(mean_imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "    # 4. KNN imputation (using 5 neighbors)\n",
    "    knn_imputer = KNNImputer(n_neighbors=3)\n",
    "    imputed_dfs[f'{key}_knn'] = pd.DataFrame(knn_imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "    # 5. Multivariate regression imputation (IterativeImputer is MICE-based)\n",
    "    mice_imputer = IterativeImputer(max_iter=5, random_state=32)\n",
    "    imputed_dfs[f'{key}_regression'] = pd.DataFrame(mice_imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import category_encoders as ce\n",
    "\n",
    "regression_results = {}\n",
    "\n",
    "for name, imputed_df in imputed_dfs.items():\n",
    "    print(f\"\\nRunning model for {name} imputed data...\")\n",
    "    X = imputed_df.copy()\n",
    "    y = y_full.reindex(X.index)\n",
    "\n",
    "    valid_idx = y.notnull()\n",
    "    X = X[valid_idx].dropna()\n",
    "    y = y.loc[X.index]\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=7)\n",
    "    y_pred = np.zeros(len(X))\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_idx].copy(), X.iloc[val_idx].copy()\n",
    "        y_train = y.iloc[train_idx]\n",
    "\n",
    "        # Target encoding within the fold\n",
    "        encoder = ce.TargetEncoder(cols=['userId', 'movieId'], smoothing=5.0)\n",
    "        encoder.fit(X_train[['userId', 'movieId']], y_train)\n",
    "\n",
    "        X_train_encoded = encoder.transform(X_train[['userId', 'movieId']])\n",
    "        X_val_encoded = encoder.transform(X_val[['userId', 'movieId']])\n",
    "\n",
    "        # Replace original IDs with encoded\n",
    "        X_train.update(X_train_encoded)\n",
    "        X_val.update(X_val_encoded)\n",
    "\n",
    "        # Train model\n",
    "        model = GradientBoostingRegressor(\n",
    "            n_estimators=150, \n",
    "            learning_rate=0.1, \n",
    "            max_depth=4, \n",
    "            random_state=72\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred[val_idx] = model.predict(X_val)\n",
    "\n",
    "    # Evaluate\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    regression_results[name] = {\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "results_5 = {method: results for method, results in regression_results.items() if method.startswith('5%')}\n",
    "results_10 = {method: results for method, results in regression_results.items() if method.startswith('10%')}\n",
    "results_15 = {method: results for method, results in regression_results.items() if method.startswith('15%')}\n",
    "\n",
    "# Convert the dictionaries into DataFrames\n",
    "df_5_results = pd.DataFrame(results_5).T\n",
    "df_10_results = pd.DataFrame(results_10).T\n",
    "df_15_results = pd.DataFrame(results_15).T\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nRegression Results for 5% Missing Data:\")\n",
    "print(df_5_results[['MAE', 'MSE', 'RMSE']].round(4))\n",
    "\n",
    "print(\"\\nRegression Results for 10% Missing Data:\")\n",
    "print(df_10_results[['MAE', 'MSE', 'RMSE']].round(4))\n",
    "\n",
    "print(\"\\nRegression Results for 15% Missing Data:\")\n",
    "print(df_15_results[['MAE', 'MSE', 'RMSE']].round(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
