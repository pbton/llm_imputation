{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e341524f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 5% missing data...\n",
      "\n",
      "Processing 10% missing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/impute/_iterative.py:895: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 15% missing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/impute/_iterative.py:895: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 20% missing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/impute/_iterative.py:895: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression Results for 5% Missing Data:\n",
      "                  MAE     MSE    RMSE\n",
      "5%_casewise    0.0382  0.0211  0.1453\n",
      "5%_zero        0.0492  0.0347  0.1862\n",
      "5%_mean        0.0407  0.0249  0.1577\n",
      "5%_knn         0.0426  0.0224  0.1495\n",
      "5%_regression  0.0394  0.0225  0.1500\n",
      "\n",
      "Regression Results for 10% Missing Data:\n",
      "                   MAE     MSE    RMSE\n",
      "10%_casewise    0.0829  0.0358  0.1892\n",
      "10%_zero        0.0846  0.0704  0.2653\n",
      "10%_mean        0.0719  0.0448  0.2117\n",
      "10%_knn         0.0852  0.0664  0.2578\n",
      "10%_regression  0.0603  0.0436  0.2088\n",
      "\n",
      "Regression Results for 15% Missing Data:\n",
      "                   MAE     MSE    RMSE\n",
      "15%_casewise    0.2830  0.2453  0.4953\n",
      "15%_zero        0.1199  0.1289  0.3590\n",
      "15%_mean        0.1110  0.0954  0.3089\n",
      "15%_knn         0.1446  0.1249  0.3535\n",
      "15%_regression  0.1166  0.1031  0.3212\n",
      "\n",
      "Regression Results for 20% Missing Data:\n",
      "                   MAE     MSE    RMSE\n",
      "20%_casewise    0.5340  0.5302  0.7281\n",
      "20%_zero        0.1311  0.1372  0.3705\n",
      "20%_mean        0.1398  0.1259  0.3548\n",
      "20%_knn         0.1696  0.1527  0.3908\n",
      "20%_regression  0.1388  0.1269  0.3562\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "rating_csv = \"/workspaces/codespaces-jupyter/data/rating.csv\"\n",
    "rating_df = pd.read_csv(rating_csv).sample(1000, random_state=955)\n",
    "\n",
    "movie_csv = \"/workspaces/codespaces-jupyter/data/movie.csv\"\n",
    "movie_df = pd.read_csv(movie_csv)\n",
    "\n",
    "# Merge the datasets\n",
    "final_df = pd.merge(movie_df, rating_df, on='movieId', how='inner')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "df = final_df.drop(columns=['title', 'timestamp'])\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Convert pipe-separated genres into space-separated strings\n",
    "df['genres'] = df['genres'].str.replace('|', ' ', regex=False)\n",
    "\n",
    "# TF-IDF transformation\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_genres = tfidf.fit_transform(df['genres'])\n",
    "tfidf_genres_df = pd.DataFrame(\n",
    "    tfidf_genres.toarray(), \n",
    "    columns=[f\"tfidf_{genre}\" for genre in tfidf.get_feature_names_out()],\n",
    "    index=df.index\n",
    ")\n",
    "\n",
    "# Drop and replace\n",
    "df = df.drop(columns=['genres'])\n",
    "df = pd.concat([df, tfidf_genres_df], axis=1)\n",
    "\n",
    "# Target encoding: Replace userId/movieId with their average rating\n",
    "user_means = df.groupby('userId')['rating'].mean()\n",
    "movie_means = df.groupby('movieId')['rating'].mean()\n",
    "\n",
    "df['userId_encoded'] = df['userId'].map(user_means)\n",
    "df['movieId_encoded'] = df['movieId'].map(movie_means)\n",
    "\n",
    "# Drop the original IDs\n",
    "df = df.drop(columns=['userId', 'movieId'])\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Store the target variable separately\n",
    "y_full = df['rating']\n",
    "\n",
    "# Create an imputation dataframe by dropping the dependent variable\n",
    "imputation_df = df.drop('rating', axis=1)\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "random.seed(29)\n",
    "np.random.seed(29)\n",
    "\n",
    "# Calculate the total number of values in the dataframe\n",
    "total_values = imputation_df.size\n",
    "\n",
    "# Function to create a dataframe with a specified percentage of missing values\n",
    "def create_missing_df(base_df, percent_missing):\n",
    "    df_missing = base_df.copy()\n",
    "    num_nulls = int(total_values * percent_missing)\n",
    "    indices = [(row, col) for row in range(df_missing.shape[0]) for col in range(df_missing.shape[1])]\n",
    "    random_indices = random.sample(indices, num_nulls)\n",
    "    for row, col in random_indices:\n",
    "        df_missing.iat[row, col] = np.nan\n",
    "    return df_missing\n",
    "\n",
    "# Create dataframes with different levels of missingness\n",
    "df_5 = create_missing_df(imputation_df, 0.05)\n",
    "df_10 = create_missing_df(imputation_df, 0.10)\n",
    "df_15 = create_missing_df(imputation_df, 0.15)\n",
    "df_20 = create_missing_df(imputation_df, 0.20)\n",
    "\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from fancyimpute import IterativeImputer  # for multivariate regression\n",
    "\n",
    "# Put all missing dataframes into a dictionary for easier looping\n",
    "missing_dfs = {\n",
    "    '5%': df_5,\n",
    "    '10%': df_10,\n",
    "    '15%': df_15,\n",
    "    '20%': df_20\n",
    "}\n",
    "\n",
    "# Store results\n",
    "imputed_dfs = {}\n",
    "\n",
    "for key, df in missing_dfs.items():\n",
    "    print(f\"\\nProcessing {key} missing data...\")\n",
    "\n",
    "    # 1. Case-wise deletion\n",
    "    imputed_dfs[f'{key}_casewise'] = df.dropna()\n",
    "\n",
    "    # 2. Fill with 0\n",
    "    imputed_dfs[f'{key}_zero'] = df.fillna(0)\n",
    "\n",
    "    # 3. Fill with mean\n",
    "    mean_imputer = SimpleImputer(strategy='mean')\n",
    "    imputed_dfs[f'{key}_mean'] = pd.DataFrame(mean_imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "    # 4. KNN imputation (using 5 neighbors)\n",
    "    knn_imputer = KNNImputer(n_neighbors=5)\n",
    "    imputed_dfs[f'{key}_knn'] = pd.DataFrame(knn_imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "    # 5. Multivariate regression imputation (IterativeImputer is MICE-based)\n",
    "    mice_imputer = IterativeImputer(random_state=42)\n",
    "    imputed_dfs[f'{key}_regression'] = pd.DataFrame(mice_imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Store results\n",
    "regression_results = {}\n",
    "\n",
    "# Loop through each imputed DataFrame\n",
    "for name, imputed_df in imputed_dfs.items():\n",
    "    # Copy the features\n",
    "    X = imputed_df.copy()\n",
    "\n",
    "    # Reindex the target variable to match X's index\n",
    "    y = y_full.reindex(X.index)\n",
    "\n",
    "    # Drop any rows where y is NaN (can happen after case-wise deletion)\n",
    "    valid_idx = y.notnull()\n",
    "    X = X[valid_idx].dropna()\n",
    "    y = y.loc[X.index]\n",
    "\n",
    "    # Define cross-validator\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=7)\n",
    "\n",
    "    # Fit and predict with cross-validation\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=72)\n",
    "    y_pred = cross_val_predict(model, X, y, cv=kf)\n",
    "\n",
    "    # Evaluate\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # Store metrics\n",
    "    regression_results[name] = {\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "results_5 = {method: results for method, results in regression_results.items() if method.startswith('5%')}\n",
    "results_10 = {method: results for method, results in regression_results.items() if method.startswith('10%')}\n",
    "results_15 = {method: results for method, results in regression_results.items() if method.startswith('15%')}\n",
    "results_20 = {method: results for method, results in regression_results.items() if method.startswith('20%')}\n",
    "\n",
    "# Convert the dictionaries into DataFrames\n",
    "df_5_results = pd.DataFrame(results_5).T\n",
    "df_10_results = pd.DataFrame(results_10).T\n",
    "df_15_results = pd.DataFrame(results_15).T\n",
    "df_20_results = pd.DataFrame(results_20).T\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nRegression Results for 5% Missing Data:\")\n",
    "print(df_5_results[['MAE', 'MSE', 'RMSE']].round(4))\n",
    "\n",
    "print(\"\\nRegression Results for 10% Missing Data:\")\n",
    "print(df_10_results[['MAE', 'MSE', 'RMSE']].round(4))\n",
    "\n",
    "print(\"\\nRegression Results for 15% Missing Data:\")\n",
    "print(df_15_results[['MAE', 'MSE', 'RMSE']].round(4))\n",
    "\n",
    "print(\"\\nRegression Results for 20% Missing Data:\")\n",
    "print(df_20_results[['MAE', 'MSE', 'RMSE']].round(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
